{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cUyHHdBYjgW8"
      },
      "outputs": [],
      "source": [
        "%pip install -q spuco torch torchvision scikit-learn tqdm matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHbLs-SJjgW9",
        "outputId": "3d2f0722-a1d0-4838-deb8-38333d67842a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, json, random, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from spuco.datasets import SpuCoMNIST, SpuriousFeatureDifficulty\n",
        "from spuco.models import model_factory\n",
        "from spuco.robust_train import ERM\n",
        "from spuco.evaluate import Evaluator\n",
        "\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.optim import SGD\n",
        "\n",
        "# -----------------\n",
        "# Global config\n",
        "# -----------------\n",
        "DEFAULT_SEED = 1234\n",
        "SCORING_BATCH_SIZE = 128\n",
        "BASE_EPOCHS = 5            # epochs when keep_ratio=1.0\n",
        "SCALE_EPOCHS_BY_KEEP = True\n",
        "EARLY_CLUSTER_WARMUP_EPOCHS = 0.5  # fractional epochs for early cluster warmup\n",
        "\n",
        "# Grids\n",
        "DIFFICULTIES = [\n",
        "    SpuriousFeatureDifficulty.MAGNITUDE_SMALL,\n",
        "    SpuriousFeatureDifficulty.MAGNITUDE_MEDIUM,\n",
        "    SpuriousFeatureDifficulty.MAGNITUDE_LARGE,\n",
        "]\n",
        "STRENGTHS = [0.9, 0.95, 0.995]\n",
        "KEEP_RATIOS = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "HEURISTICS = [\n",
        "    \"base_line\",\n",
        "    \"random\",\n",
        "    \"loss\",\n",
        "    \"gradnorm\",\n",
        "    \"confident\",\n",
        "    \"entropy\",\n",
        "    \"forgetting\",\n",
        "    \"early_cluster\",\n",
        "    \"rmi\",\n",
        "]\n",
        "\n",
        "LOG_DIR = \"logs_spuco_grid\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "def set_seeds(seed: int = DEFAULT_SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "set_seeds(DEFAULT_SEED)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bPfGGYaDjgW-"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Dataset builder\n",
        "# -----------------\n",
        "\n",
        "def build_datasets(difficulty, strength):\n",
        "    classes = [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n",
        "    trainset = SpuCoMNIST(\n",
        "        root=\"data/dataset\",\n",
        "        split=\"train\",\n",
        "        classes=classes,\n",
        "        spurious_feature_difficulty=difficulty,\n",
        "        spurious_correlation_strength=strength,\n",
        "    )\n",
        "    trainset.initialize()\n",
        "    testset = SpuCoMNIST(\n",
        "        root=\"data/dataset\",\n",
        "        split=\"test\",\n",
        "        classes=classes,\n",
        "        spurious_feature_difficulty=difficulty,\n",
        "        spurious_correlation_strength=strength,\n",
        "    )\n",
        "    testset.initialize()\n",
        "    return trainset, testset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UtpoB3zdjgW-"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Heuristic utilities\n",
        "# -----------------\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_losses(model, dataset, device):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "    crit = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss_vals = crit(logits, y)\n",
        "        losses.extend(loss_vals.cpu().numpy())\n",
        "    return np.array(losses)\n",
        "\n",
        "\n",
        "def compute_gradnorms(model, dataset, device):\n",
        "    model.eval()\n",
        "    grad_norms = []\n",
        "    crit = torch.nn.CrossEntropyLoss()\n",
        "    for i in range(len(dataset)):\n",
        "        x, y = dataset[i]\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        y = torch.tensor([y]).to(device)\n",
        "        model.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = crit(out, y)\n",
        "        loss.backward()\n",
        "        total_norm = 0\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                total_norm += p.grad.detach().norm().item()\n",
        "        grad_norms.append(total_norm)\n",
        "    return np.array(grad_norms)\n",
        "\n",
        "\n",
        "def compute_confidence(model, dataset, device):\n",
        "    model.eval()\n",
        "    conf = []\n",
        "    loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "    softmax = torch.nn.Softmax(dim=1)\n",
        "    with torch.no_grad():\n",
        "        for x, _ in loader:\n",
        "            x = x.to(device)\n",
        "            p = softmax(model(x))\n",
        "            max_conf = p.max(dim=1).values\n",
        "            conf.extend(max_conf.cpu().numpy())\n",
        "    return np.array(conf)\n",
        "\n",
        "\n",
        "def compute_entropy(model, dataset, device):\n",
        "    model.eval()\n",
        "    ent = []\n",
        "    log_softmax = torch.nn.LogSoftmax(dim=1)\n",
        "    loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "    with torch.no_grad():\n",
        "        for x, _ in loader:\n",
        "            x = x.to(device)\n",
        "            logits = model(x)\n",
        "            logp = log_softmax(logits)\n",
        "            p = torch.exp(logp)\n",
        "            entropy_vals = -(p * logp).sum(dim=1)\n",
        "            ent.extend(entropy_vals.cpu().numpy())\n",
        "    return np.array(ent)\n",
        "\n",
        "\n",
        "def compute_forgetting_events(model, dataset, device, warmup_epochs=8):\n",
        "    n = len(dataset)\n",
        "    seen_correct = np.zeros(n, dtype=bool)\n",
        "    forget_count = np.zeros(n)\n",
        "    loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=2)\n",
        "    crit = torch.nn.CrossEntropyLoss()\n",
        "    opt = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "    for epoch in range(warmup_epochs):\n",
        "        for batch_idx, (x, y) in enumerate(loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            model.train()\n",
        "            opt.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = crit(logits, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct = (pred == y).cpu().numpy()\n",
        "            start = batch_idx * loader.batch_size\n",
        "            end = start + len(y)\n",
        "            global_indices = np.arange(start, end)\n",
        "            for i, idx in enumerate(global_indices):\n",
        "                if seen_correct[idx] and not correct[i]:\n",
        "                    forget_count[idx] += 1\n",
        "                seen_correct[idx] = correct[i]\n",
        "    return forget_count\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_representations(model, dataset, device, batch_size=256):\n",
        "    model.eval()\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    reps = []\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        f = model.forward(x)\n",
        "        reps.append(f.cpu())\n",
        "    reps = torch.cat(reps, dim=0).numpy()\n",
        "    return reps\n",
        "\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def fast_craig_select(reps, budget):\n",
        "    km = KMeans(n_clusters=budget, init='k-means++', n_init=1, max_iter=1, random_state=DEFAULT_SEED)\n",
        "    km.fit(reps)\n",
        "    centers = km.cluster_centers_\n",
        "    idxs = []\n",
        "    for c in centers:\n",
        "        d = np.linalg.norm(reps - c, axis=1)\n",
        "        idxs.append(np.argmin(d))\n",
        "    return np.array(idxs, dtype=int)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_feature_centroids(model, dataset, device):\n",
        "    model.eval()\n",
        "    loader = DataLoader(dataset, batch_size=SCORING_BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "    feats_by_class = {}\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        f = model.forward(x).cpu().numpy()\n",
        "        y = y.numpy()\n",
        "        for fi, yi in zip(f, y):\n",
        "            feats_by_class.setdefault(yi, []).append(fi)\n",
        "    centroids = {c: np.mean(np.stack(v), axis=0) for c, v in feats_by_class.items()}\n",
        "    return centroids\n",
        "\n",
        "\n",
        "def compute_rmi(model, dataset, device):\n",
        "    \"\"\"Representation-Margin Influence heuristic.\"\"\"\n",
        "    model.eval()\n",
        "    centroids = compute_feature_centroids(model, dataset, device)\n",
        "    rmi_scores = []\n",
        "    loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "    crit = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = crit(logits, y)\n",
        "        loss.backward()\n",
        "\n",
        "        grad_norm_sq = sum(\n",
        "            (p.grad.detach().norm() ** 2 for p in model.parameters() if p.grad is not None)\n",
        "        )\n",
        "        grad_influence = grad_norm_sq.sqrt().item()\n",
        "\n",
        "        f = model.forward(x).detach().cpu().numpy()[0]\n",
        "        y_class = int(y.cpu().item())\n",
        "        margins = []\n",
        "        for c, mu in centroids.items():\n",
        "            if c == y_class:\n",
        "                continue\n",
        "            margin = np.linalg.norm(f - mu)\n",
        "            margins.append(margin)\n",
        "        margin = min(margins) if margins else 1.0\n",
        "\n",
        "        rmi_scores.append(grad_influence / margin)\n",
        "\n",
        "    return np.array(rmi_scores)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KnJ9XYExjgW_"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Early Loss Cluster warmup + selection + training/eval\n",
        "# -----------------\n",
        "\n",
        "def warmup_model_for_scoring(model, dataset, device,\n",
        "                             epochs=5,\n",
        "                             batch_size=SCORING_BATCH_SIZE,\n",
        "                             lr=1e-2):\n",
        "    model.train()\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    num_steps = int(max(1, epochs * len(loader)))  # len(loader) ~ ceil(N / batch_size)\n",
        "    opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True)\n",
        "    crit = torch.nn.CrossEntropyLoss()\n",
        "    step = 0\n",
        "    while step < num_steps:\n",
        "        for x, y in loader:\n",
        "            if step >= num_steps:\n",
        "                break\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = crit(logits, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            step += 1\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def early_loss_cluster_prune(trainset, model, device, keep_ratio):\n",
        "    warmup_model_for_scoring(model, trainset, device)\n",
        "    losses = compute_losses(model, trainset, device)\n",
        "    kmeans = KMeans(n_clusters=2, random_state=DEFAULT_SEED)\n",
        "    labels = kmeans.fit_predict(losses.reshape(-1, 1))\n",
        "    cluster_means = [losses[labels == k].mean() for k in range(2)]\n",
        "    low_loss_cluster = np.argmin(cluster_means)\n",
        "    high_loss_indices = np.where(labels != low_loss_cluster)[0]\n",
        "    low_loss_indices = np.where(labels == low_loss_cluster)[0]\n",
        "\n",
        "    topk = int(len(trainset) * keep_ratio)\n",
        "    chosen = list(high_loss_indices)\n",
        "    if len(chosen) < topk:\n",
        "        need = topk - len(chosen)\n",
        "        fill = np.random.choice(low_loss_indices, need, replace=False)\n",
        "        chosen = np.concatenate([chosen, fill])\n",
        "    else:\n",
        "        chosen = np.random.choice(chosen, topk, replace=False)\n",
        "\n",
        "    subset = Subset(trainset, chosen)\n",
        "    subset = attach_subset_metadata(subset, trainset)\n",
        "    print(f\"[early_cluster] keep_ratio={keep_ratio}, target={topk}, high_loss={len(high_loss_indices)}, low_loss={len(low_loss_indices)}, selected={len(chosen)}\")\n",
        "    return subset\n",
        "\n",
        "\n",
        "def attach_subset_metadata(subset, original_dataset):\n",
        "    for attr in [\"group_weights\", \"group_partition\", \"groups\"]:\n",
        "        if hasattr(original_dataset, attr):\n",
        "            setattr(subset, attr, getattr(original_dataset, attr))\n",
        "    return subset\n",
        "\n",
        "\n",
        "def select_data_heuristic(trainset, model, heuristic, keep_ratio):\n",
        "    n = len(trainset)\n",
        "\n",
        "    if heuristic == \"random\":\n",
        "        idx = np.random.choice(n, int(n * keep_ratio), replace=False)\n",
        "\n",
        "    elif heuristic == \"loss\":\n",
        "        losses = compute_losses(model, trainset, device)\n",
        "        topk = int(n * keep_ratio)\n",
        "        idx = np.argsort(losses)[-topk:]\n",
        "\n",
        "    elif heuristic == \"gradnorm\":\n",
        "        gradnorms = compute_gradnorms(model, trainset, device)\n",
        "        topk = int(n * keep_ratio)\n",
        "        idx = np.argsort(gradnorms)[-topk:]\n",
        "\n",
        "    elif heuristic == \"confident\":\n",
        "        conf = compute_confidence(model, trainset, device)\n",
        "        topk = int(n * keep_ratio)\n",
        "        idx = np.argsort(conf)[:topk]\n",
        "\n",
        "    elif heuristic == \"entropy\":\n",
        "        ent = compute_entropy(model, trainset, device)\n",
        "        topk = int(n * keep_ratio)\n",
        "        idx = np.argsort(ent)[-topk:]\n",
        "\n",
        "    elif heuristic == \"forgetting\":\n",
        "        forgets = compute_forgetting_events(model, trainset, device)\n",
        "        topk = int(n * keep_ratio)\n",
        "        idx = np.argsort(forgets)[-topk:]\n",
        "\n",
        "    elif heuristic == \"early_cluster\":\n",
        "        return early_loss_cluster_prune(trainset, model, device, keep_ratio)\n",
        "\n",
        "    elif heuristic == \"rmi\":\n",
        "        scores = compute_rmi(model, trainset, device)\n",
        "        topk = int(len(trainset) * keep_ratio)\n",
        "        idx = np.argsort(scores)[-topk:]\n",
        "\n",
        "    elif heuristic == \"craig\":\n",
        "        reps = compute_representations(model, trainset, device)\n",
        "        budget = int(n * keep_ratio)\n",
        "        idx = fast_craig_select(reps, budget)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown heuristic: {heuristic}\")\n",
        "\n",
        "    subset = Subset(trainset, idx)\n",
        "    subset = attach_subset_metadata(subset, trainset)\n",
        "    return subset\n",
        "\n",
        "\n",
        "def train_and_eval(train_subset, testset, name, keep_ratio):\n",
        "    epochs = BASE_EPOCHS\n",
        "    if SCALE_EPOCHS_BY_KEEP and keep_ratio > 0:\n",
        "        epochs = max(1, int(round(BASE_EPOCHS / keep_ratio)))\n",
        "\n",
        "    model = model_factory(\"lenet\", train_subset[0][0].shape, train_subset.dataset.num_classes).to(device)\n",
        "    optimizer = SGD(model.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
        "\n",
        "    erm = ERM(\n",
        "        trainset=train_subset,\n",
        "        model=model,\n",
        "        num_epochs=epochs,\n",
        "        batch_size=128,\n",
        "        optimizer=optimizer,\n",
        "        device=device,\n",
        "        verbose=False,\n",
        "    )\n",
        "    erm.train()\n",
        "\n",
        "    evaluator = Evaluator(\n",
        "        testset=testset,\n",
        "        group_partition=testset.group_partition,\n",
        "        group_weights=testset.group_weights,\n",
        "        batch_size=64,\n",
        "        model=model,\n",
        "        device=device,\n",
        "        verbose=False,\n",
        "    )\n",
        "    evaluator.evaluate()\n",
        "\n",
        "    return evaluator.worst_group_accuracy, evaluator.average_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LTgOWsTBjgXA"
      },
      "outputs": [],
      "source": [
        "# -----------------\n",
        "# Logging utilities\n",
        "# -----------------\n",
        "import csv\n",
        "\n",
        "def init_csv(log_path):\n",
        "    header = [\"seed\", \"difficulty\", \"strength\", \"keep_ratio\", \"heuristic\",\n",
        "              \"worst_group_acc\", \"average_acc\", \"timestamp\"]\n",
        "    if not os.path.exists(log_path):\n",
        "        with open(log_path, \"w\", newline=\"\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(header)\n",
        "\n",
        "\n",
        "def append_csv(log_path, row):\n",
        "    with open(log_path, \"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(row)\n",
        "\n",
        "\n",
        "def save_barplot(worst_dict, avg_dict, out_path_prefix):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    axes[0].bar(list(worst_dict.keys()), list(worst_dict.values()), color='skyblue')\n",
        "    axes[0].set_ylabel(\"Worst Group Accuracy\")\n",
        "    axes[0].set_title(\"Worst Group Accuracy Across Heuristics\")\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    axes[1].bar(list(avg_dict.keys()), list(avg_dict.values()), color='salmon')\n",
        "    axes[1].set_ylabel(\"Average Accuracy\")\n",
        "    axes[1].set_title(\"Average Accuracy Across Heuristics\")\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path_prefix + \"_bars.png\", dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "def save_text_log(text, out_path):\n",
        "    with open(out_path, \"w\") as f:\n",
        "        f.write(text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iCVVLawIjgXA",
        "outputId": "4bfee2ca-a10c-492a-c5dc-487e4e41f3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Difficulty=SpuriousFeatureDifficulty.MAGNITUDE_SMALL, Strength=0.9 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 494kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.5MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- keep_ratio=0.1 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:08<00:00,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 92.9471032745592), Avg: 97.08999999999999\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:06<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 82.36775818639798), Avg: 97.39\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 61.20906801007557), Avg: 94.39000000000001\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:06<00:00,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 71.28463476070529), Avg: 96.56000000000002\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((1, 2), 89.2156862745098), Avg: 96.76000000000002\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 88.66498740554157), Avg: 95.18\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.1, target=4800, high_loss=311, low_loss=47693, selected=4800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:06<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 92.24598930481284), Avg: 97.00999999999999\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 70.52896725440806), Avg: 94.08999999999997\n",
            "-- keep_ratio=0.3 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 96.2566844919786), Avg: 98.10999999999999\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 94.20654911838791), Avg: 98.33\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((3, 3), 97.48110831234257), Avg: 98.92\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 88.66498740554157), Avg: 98.05000000000001\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:06<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 91.71122994652407), Avg: 98.27\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 89.16876574307305), Avg: 97.66\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.3, target=14401, high_loss=311, low_loss=47693, selected=14401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((3, 1), 90.17632241813602), Avg: 97.17999999999999\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 83.1234256926952), Avg: 97.78999999999999\n",
            "-- keep_ratio=0.5 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 4), 96.46464646464646), Avg: 98.21\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 4), 96.96969696969697), Avg: 98.68999999999997\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 96.524064171123), Avg: 98.75000000000003\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 96.524064171123), Avg: 98.53\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 88.41309823677582), Avg: 97.97999999999998\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 93.58288770053476), Avg: 98.24\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.5, target=24002, high_loss=311, low_loss=47693, selected=24002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((3, 3), 95.21410579345088), Avg: 98.13999999999999\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((3, 3), 96.72544080604534), Avg: 98.78999999999999\n",
            "-- keep_ratio=0.7 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 95.45454545454545), Avg: 98.08999999999999\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:08<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 96.79144385026738), Avg: 98.84\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 94.6524064171123), Avg: 98.49000000000001\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:08<00:00,  3.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 4), 96.96969696969697), Avg: 98.65000000000002\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 96.4735516372796), Avg: 98.63\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 87.16577540106952), Avg: 97.75000000000001\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.7, target=33602, high_loss=311, low_loss=47693, selected=33602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:08<00:00,  3.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((3, 3), 95.96977329974811), Avg: 98.39999999999998\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 95.72192513368984), Avg: 98.54000000000002\n",
            "-- keep_ratio=0.9 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 93.85026737967914), Avg: 98.01\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 96.524064171123), Avg: 98.63000000000001\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 94.7103274559194), Avg: 98.05\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 96.97732997481108), Avg: 98.69000000000003\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 81.01604278074866), Avg: 97.29\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 4), 95.20202020202021), Avg: 98.36999999999996\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.9, target=43203, high_loss=311, low_loss=47693, selected=43203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((3, 1), 95.71788413098237), Avg: 98.14\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:07<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 96.2566844919786), Avg: 98.53999999999999\n",
            "\n",
            "=== Difficulty=SpuriousFeatureDifficulty.MAGNITUDE_SMALL, Strength=0.95 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:08<00:00,  2.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- keep_ratio=0.1 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:08<00:00,  2.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 1), 94.93333333333334), Avg: 97.11\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 52.94117647058823), Avg: 93.91000000000003\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 28.609625668449198), Avg: 89.23999999999998\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 79.14438502673796), Avg: 97.2\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:08<00:00,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 1), 45.84382871536524), Avg: 90.45000000000003\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 3), 86.13333333333334), Avg: 95.17999999999999\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.1, target=4800, high_loss=345, low_loss=47659, selected=4800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 0), 93.70277078085643), Avg: 97.18000000000002\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 39.839572192513366), Avg: 93.31\n",
            "-- keep_ratio=0.3 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 0), 94.20654911838791), Avg: 97.82000000000001\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 92.51336898395722), Avg: 98.53000000000003\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 3), 89.39393939393939), Avg: 96.99999999999999\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 69.25133689839572), Avg: 95.84\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 0), 93.95465994962217), Avg: 98.24000000000001\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 2), 95.73333333333333), Avg: 98.32999999999998\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.3, target=14401, high_loss=345, low_loss=47659, selected=14401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:10<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 65.74307304785894), Avg: 95.59999999999998\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 69.5187165775401), Avg: 96.49\n",
            "-- keep_ratio=0.5 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((3, 4), 95.71788413098237), Avg: 97.97000000000001\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:10<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 0), 95.46599496221663), Avg: 98.41000000000001\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:10<00:00,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 88.23529411764706), Avg: 97.12\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:10<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 89.3048128342246), Avg: 97.75000000000001\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:10<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 77.27272727272727), Avg: 96.77000000000001\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 2), 94.66666666666667), Avg: 98.35000000000001\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.5, target=24002, high_loss=345, low_loss=47659, selected=24002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 77.32997481108312), Avg: 96.00999999999998\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:10<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 91.97860962566845), Avg: 97.77999999999999\n",
            "-- keep_ratio=0.7 --\n",
            "   Heuristic: base_line\n",
            "   Heuristic: random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:10<00:00,  2.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((3, 3), 97.22921914357683), Avg: 98.37999999999998\n",
            "   Heuristic: loss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:10<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((0, 4), 91.725768321513), Avg: 97.49999999999999\n",
            "   Heuristic: gradnorm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 2), 69.52141057934509), Avg: 96.7\n",
            "   Heuristic: confident\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 89.03743315508021), Avg: 97.67999999999999\n",
            "   Heuristic: entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((4, 3), 97.22222222222223), Avg: 98.78\n",
            "   Heuristic: forgetting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 1), 95.46666666666667), Avg: 98.36999999999999\n",
            "   Heuristic: early_cluster\n",
            "[early_cluster cached] keep_ratio=0.7, target=33602, high_loss=345, low_loss=47659, selected=33602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Evaluating group-wise accuracy: 100%|██████████| 25/25 [00:09<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Done. Worst group: ((2, 4), 85.8288770053476), Avg: 97.5\n",
            "   Heuristic: rmi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-278257441.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mscoring_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring_model_forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                     \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_heuristic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mwg_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheuristic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2069023195.py\u001b[0m in \u001b[0;36mselect_data_heuristic\u001b[0;34m(trainset, model, heuristic, keep_ratio)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mheuristic\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"rmi\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_rmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mtopk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkeep_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3955661463.py\u001b[0m in \u001b[0;36mcompute_rmi\u001b[0;34m(model, dataset, device)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mcrit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey, digest_name)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[0;31m# digest prefixes, they'll take the entire thing as a challenge and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;31m# respond to it with a raw HMAC-MD5.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CHALLENGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend_bytes\u001b[0;34m(self, buf, offset, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"buffer length < offset + size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;31m# Also note we want to avoid sending a 0-length buffer separately,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;31m# to avoid \"broken pipe\" errors if the other end closed the pipe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, buf, write)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mremaining\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# -----------------\n",
        "# Experiment loop (dry-run ready)\n",
        "# -----------------\n",
        "\n",
        "log_csv = os.path.join(LOG_DIR, \"results.csv\")\n",
        "init_csv(log_csv)\n",
        "\n",
        "results = []\n",
        "\n",
        "for difficulty in DIFFICULTIES:\n",
        "    for strength in STRENGTHS:\n",
        "        print(f\"\\n=== Difficulty={difficulty}, Strength={strength} ===\")\n",
        "        trainset, testset = build_datasets(difficulty, strength)\n",
        "\n",
        "        # Baseline (full data)\n",
        "        model_lenet = model_factory(\"lenet\", trainset[0][0].shape, trainset.num_classes).to(device)\n",
        "        optimizer = SGD(model_lenet.parameters(), lr=1e-2, momentum=0.9, nesterov=True)\n",
        "        erm_full = ERM(\n",
        "            trainset=trainset,\n",
        "            model=model_lenet,\n",
        "            num_epochs=BASE_EPOCHS,\n",
        "            batch_size=128,\n",
        "            optimizer=optimizer,\n",
        "            device=device,\n",
        "            verbose=False,\n",
        "        )\n",
        "        erm_full.train()\n",
        "\n",
        "        evaluator = Evaluator(\n",
        "            testset=testset,\n",
        "            group_partition=testset.group_partition,\n",
        "            group_weights=testset.group_weights,\n",
        "            batch_size=64,\n",
        "            model=model_lenet,\n",
        "            device=device,\n",
        "            verbose=False,\n",
        "        )\n",
        "        evaluator.evaluate()\n",
        "        baseline_wg = evaluator.worst_group_accuracy\n",
        "        baseline_avg = evaluator.average_accuracy\n",
        "\n",
        "        baseline_row = {\n",
        "            \"seed\": DEFAULT_SEED,\n",
        "            \"difficulty\": str(difficulty),\n",
        "            \"strength\": strength,\n",
        "            \"keep_ratio\": 1.0,\n",
        "            \"heuristic\": \"base_line\",\n",
        "            \"worst_group_acc\": baseline_wg[1] if isinstance(baseline_wg, tuple) else baseline_wg,\n",
        "            \"average_acc\": baseline_avg,\n",
        "        }\n",
        "\n",
        "        results.append(baseline_row)\n",
        "        append_csv(log_csv, [DEFAULT_SEED, difficulty, strength, 1.0, \"base_line\", baseline_row[\"worst_group_acc\"], baseline_avg, time.time()])\n",
        "\n",
        "        # Precompute scoring for forgetting / early_cluster once per (difficulty, strength)\n",
        "        forgetting_scores = None\n",
        "        early_losses = None\n",
        "        early_kmeans = None\n",
        "        high_loss_indices = None\n",
        "        low_loss_indices = None\n",
        "\n",
        "        # Scoring model for forward-only heuristics: reuse trained baseline\n",
        "        scoring_model_forward = model_lenet\n",
        "\n",
        "        # For forgetting: train a small warmup model once, compute forgetting counts once\n",
        "        forget_model = model_factory(\"lenet\", trainset[0][0].shape, trainset.num_classes).to(device)\n",
        "        forgetting_scores = compute_forgetting_events(forget_model, trainset, device)\n",
        "\n",
        "        # For early_cluster: warm up once and cache losses/cluster splits\n",
        "        early_model = model_factory(\"lenet\", trainset[0][0].shape, trainset.num_classes).to(device)\n",
        "        warmup_model_for_scoring(early_model, trainset, device)\n",
        "        early_losses = compute_losses(early_model, trainset, device)\n",
        "        early_kmeans = KMeans(n_clusters=2, random_state=DEFAULT_SEED)\n",
        "        labels = early_kmeans.fit_predict(early_losses.reshape(-1, 1))\n",
        "        cluster_means = [early_losses[labels == k].mean() for k in range(2)]\n",
        "        low_loss_cluster = np.argmin(cluster_means)\n",
        "        high_loss_indices = np.where(labels != low_loss_cluster)[0]\n",
        "        low_loss_indices = np.where(labels == low_loss_cluster)[0]\n",
        "\n",
        "        def select_early_cached(trainset, keep_ratio):\n",
        "            topk = int(len(trainset) * keep_ratio)\n",
        "            chosen = list(high_loss_indices)\n",
        "            if len(chosen) < topk:\n",
        "                need = topk - len(chosen)\n",
        "                fill = np.random.choice(low_loss_indices, need, replace=False)\n",
        "                chosen = np.concatenate([chosen, fill])\n",
        "            else:\n",
        "                chosen = np.random.choice(chosen, topk, replace=False)\n",
        "            subset = Subset(trainset, chosen)\n",
        "            subset = attach_subset_metadata(subset, trainset)\n",
        "            print(f\"[early_cluster cached] keep_ratio={keep_ratio}, target={topk}, high_loss={len(high_loss_indices)}, low_loss={len(low_loss_indices)}, selected={len(chosen)}\")\n",
        "            return subset\n",
        "\n",
        "        def select_forgetting_cached(trainset, keep_ratio):\n",
        "            topk = int(len(trainset) * keep_ratio)\n",
        "            idx = np.argsort(forgetting_scores)[-topk:]\n",
        "            subset = Subset(trainset, idx)\n",
        "            subset = attach_subset_metadata(subset, trainset)\n",
        "            return subset\n",
        "\n",
        "        # For each keep_ratio and heuristic\n",
        "        for keep_ratio in KEEP_RATIOS:\n",
        "            print(f\"-- keep_ratio={keep_ratio} --\")\n",
        "            for heuristic in HEURISTICS:\n",
        "                print(f\"   Heuristic: {heuristic}\")\n",
        "                if heuristic == \"base_line\":\n",
        "                    continue\n",
        "\n",
        "                if heuristic == \"forgetting\":\n",
        "                    subset = select_forgetting_cached(trainset, keep_ratio)\n",
        "                    scoring_model = scoring_model_forward  # irrelevant; subset already chosen\n",
        "                elif heuristic == \"early_cluster\":\n",
        "                    subset = select_early_cached(trainset, keep_ratio)\n",
        "                    scoring_model = scoring_model_forward\n",
        "                else:\n",
        "                    scoring_model = scoring_model_forward\n",
        "                    subset = select_data_heuristic(trainset, scoring_model, heuristic, keep_ratio)\n",
        "\n",
        "                wg_acc, avg_acc = train_and_eval(subset, testset, heuristic, keep_ratio)\n",
        "                print(f\"      Done. Worst group: {wg_acc}, Avg: {avg_acc}\")\n",
        "\n",
        "                row = {\n",
        "                    \"seed\": DEFAULT_SEED,\n",
        "                    \"difficulty\": str(difficulty),\n",
        "                    \"strength\": strength,\n",
        "                    \"keep_ratio\": keep_ratio,\n",
        "                    \"heuristic\": heuristic,\n",
        "                    \"worst_group_acc\": wg_acc[1] if isinstance(wg_acc, tuple) else wg_acc,\n",
        "                    \"average_acc\": avg_acc,\n",
        "                }\n",
        "                results.append(row)\n",
        "                append_csv(log_csv, [DEFAULT_SEED, difficulty, strength, keep_ratio, heuristic, row[\"worst_group_acc\"], avg_acc, time.time()])\n",
        "\n",
        "            # Per-config plots\n",
        "            worst_dict = {}\n",
        "            avg_dict = {}\n",
        "            for r in results:\n",
        "                if r[\"difficulty\"] == str(difficulty) and r[\"strength\"] == strength and r[\"keep_ratio\"] == keep_ratio:\n",
        "                    worst_dict[r[\"heuristic\"]] = r[\"worst_group_acc\"]\n",
        "                    avg_dict[r[\"heuristic\"]] = r[\"average_acc\"]\n",
        "            out_prefix = os.path.join(LOG_DIR, f\"diff_{difficulty}_str_{strength}_kr_{keep_ratio}\")\n",
        "            save_barplot(worst_dict, avg_dict, out_prefix)\n",
        "\n",
        "# Save a JSON summary\n",
        "with open(os.path.join(LOG_DIR, \"results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"Done. Logs saved to\", LOG_DIR)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}